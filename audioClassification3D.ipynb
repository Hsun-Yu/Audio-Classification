{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_pad_len = 216\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "or_wood_knock\nclapping\nclapping\nclapping\ndog\nclapping\nthunderstorm\nfireworks\nfireworks\nfireworks\nfireworks\nclapping\nclapping\nclapping\nchainsaw\nairplane\nmouse_click\npouring_water\ntrain\nsheep\nwater_drops\nwater_drops\nwater_drops\nchurch_bells\nchurch_bells\nclock_alarm\nkeyboard_typing\nwind\nclock_alarm\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfrog\nfrog\nfireworks\nfireworks\ncow\nwater_drops\nbrushing_teeth\nbrushing_teeth\ncar_horn\ncrackling_fire\nhelicopter\nhelicopter\nhelicopter\nhelicopter\nhelicopter\nhelicopter\ndrinking_sipping\nrain\ncrackling_fire\ninsects\ncrackling_fire\ncrackling_fire\ncrackling_fire\nlaughing\nfrog\nhen\nhen\nhelicopter\nhelicopter\nengine\nengine\nbreathing\nmouse_click\ncrying_baby\nfrog\nfrog\nfrog\nhand_saw\ncar_horn\ncoughing\ncoughing\ninsects\nsheep\nsheep\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nchainsaw\nchainsaw\nchainsaw\nglass_breaking\ncow\nsnoring\ntoilet_flush\npig\npig\npig\npig\npig\ncrying_baby\ncrying_baby\ncrying_baby\nrain\nchurch_bells\nwashing_machine\nclock_tick\nclock_tick\nfootsteps\ncrying_baby\ncrying_baby\nchurch_bells\nengine\nwater_drops\nwater_drops\nthunderstorm\nthunderstorm\nhand_saw\nwashing_machine\nwashing_machine\ncar_horn\ncar_horn\nthunderstorm\nthunderstorm\nthunderstorm\nairplane\ncar_horn\nfireworks\nfireworks\npig\npig\npig\nsneezing\ncar_horn\ncar_horn\ndoor_wood_knock\nrain\nrooster\nwashing_machine\nwashing_machine\nsnoring\nsnoring\nrooster\ntoilet_flush\nsea_waves\nsea_waves\ncar_horn\nwind\nrain\nsneezing\nlaughing\nlaughing\ntoilet_flush\ndog\ndog\nbreathing\nbreathing\nbreathing\ncoughing\nhen\nhen\nsiren\nsiren\nsneezing\nfrog\nfrog\ndog\nwashing_machine\nwashing_machine\ndrinking_sipping\nlaughing\ncat\ncat\nrooster\nrooster\nchirping_birds\nchirping_birds\nclock_alarm\nclock_tick\nlaughing\nlaughing\nbreathing\nbreathing\nbreathing\nbreathing\nairplane\ndrinking_sipping\nchirping_birds\nchirping_birds\ncrow\ncrow\nsea_waves\nsea_waves\nrooster\nsnoring\nchurch_bells\nsnoring\nrooster\nsnoring\ncan_opening\ncrackling_fire\nclock_tick\nrooster\nsea_waves\ncan_opening\nairplane\nairplane\nairplane\nairplane\nrooster\nbrushing_teeth\nmouse_click\nchirping_birds\ncrackling_fire\ntoilet_flush\nhand_saw\nvacuum_cleaner\ninsects\ninsects\nchainsaw\nchainsaw\nsneezing\nsneezing\nwind\nwind\ncat\ncat\ncat\nsnoring\nchurch_bells\nclock_tick\nwashing_machine\nsheep\nsheep\nrain\nengine\nengine\nwater_drops\npouring_water\nengine\npouring_water\nwind\nwind\nwind\nfootsteps\ntoilet_flush\npouring_water\npouring_water\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ncoughing\ndoor_wood_knock\ncoughing\nsnoring\nairplane\nkeyboard_typing\ncoughing\ntoilet_flush\ntrain\ntrain\nsiren\nsneezing\nchurch_bells\ntoilet_flush\nchirping_birds\nchirping_birds\nrain\ncrow\ncrow\ntoilet_flush\ndrinking_sipping\nrain\ncat\ncat\nchurch_bells\nclock_tick\ncrickets\ncrickets\nsheep\ncow\ncoughing\ncan_opening\nbrushing_teeth\nbrushing_teeth\ncrickets\nsneezing\ndog\nhen\nvacuum_cleaner\ncan_opening\ncrying_baby\ncrying_baby\nkeyboard_typing\npouring_water\nsea_waves\nengine\nbrushing_teeth\ntrain\nengine\nkeyboard_typing\nclock_tick\nclock_tick\ncoughing\nrain\nchainsaw\nchainsaw\ntrain\ncrickets\nclock_alarm\npouring_water\ndrinking_sipping\nbrushing_teeth\nbrushing_teeth\ncan_opening\ncan_opening\ncan_opening\ncow\ncow\nwind\ntrain\ncrackling_fire\nhen\nclock_alarm\nclock_alarm\nhen\nhen\nlaughing\nlaughing\ninsects\nclock_alarm\ncrickets\ncrow\ninsects\nsheep\nsiren\nsiren\nsiren\nsiren\nsiren\ncow\ncow\ncat\ndrinking_sipping\npouring_water\nvacuum_cleaner\nkeyboard_typing\ninsects\nhand_saw\nhand_saw\ninsects\ncrickets\ncrickets\ndoor_wood_knock\ndoor_wood_knock\ncow\nmouse_click\nsneezing\ndoor_wood_knock\nkeyboard_typing\nglass_breaking\nglass_breaking\nglass_breaking\nmouse_click\nglass_breaking\nglass_breaking\ndog\ndrinking_sipping\ndrinking_sipping\ntrain\ntrain\nsheep\nglass_breaking\nwater_drops\nsea_waves\nsea_waves\nclapping\nkeyboard_typing\nkeyboard_typing\nmouse_click\nclock_alarm\ncrow\ncrow\ndog\nglass_breaking\nmouse_click\ncrickets\nhand_saw\nhand_saw\nhand_saw\nmouse_click\ncar_horn\nrooster\nrain\npouring_water\npouring_water\npouring_water\npouring_water\npouring_water\npouring_water\npouring_water\nclock_alarm\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\ndrinking_sipping\ndrinking_sipping\nsea_waves\ncow\ncow\ncow\ncow\ncow\nthunderstorm\nthunderstorm\nkeyboard_typing\nclock_alarm\nclock_alarm\ncow\nwind\nwind\nairplane\nengine\nengine\nengine\ncrickets\nvacuum_cleaner\nvacuum_cleaner\nengine\nengine\nairplane\nglass_breaking\nengine\nengine\ncrying_baby\ncrying_baby\ncoughing\nchirping_birds\nchirping_birds\nchirping_birds\ncrow\ncrow\ncrow\ncrow\ncrow\ncrow\ncrow\ncrow\nkeyboard_typing\nwind\nwind\nwind\nwind\nwind\nsneezing\nlaughing\nlaughing\ncat\ncat\nsnoring\nsnoring\ncrickets\nsheep\nsheep\nglass_breaking\nglass_breaking\ndoor_wood_knock\ndog\ndog\nsnoring\nsnoring\ndog\nclock_alarm\ndog\nsnoring\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nrain\ncow\ncow\ndog\nsneezing\nkeyboard_typing\nkeyboard_typing\ndoor_wood_knock\ndoor_wood_knock\nkeyboard_typing\ndog\nsneezing\nmouse_click\nsheep\nsheep\nsheep\nclock_tick\ndoor_wood_knock\ndoor_wood_knock\nkeyboard_typing\nhen\nhen\nwashing_machine\ndrinking_sipping\ntrain\ntrain\ntrain\ntrain\ndog\ndog\nchirping_birds\ndrinking_sipping\ndrinking_sipping\nvacuum_cleaner\nvacuum_cleaner\ndoor_wood_creaks\ncoughing\nwater_drops\nsea_waves\ncar_horn\ncrickets\ncrickets\nsea_waves\npouring_water\ndrinking_sipping\nclock_tick\nhen\ncar_horn\ncar_horn\nsneezing\ncan_opening\nsneezing\nsneezing\nclock_tick\nsea_waves\nsea_waves\nsea_waves\ndoor_wood_knock\nhen\nclock_tick\ndoor_wood_knock\ntrain\ntrain\ntrain\nclock_tick\nhand_saw\nsea_waves\nmouse_click\ncar_horn\nwater_drops\nwater_drops\nwater_drops\nclock_tick\ndoor_wood_knock\nglass_breaking\nclock_tick\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\ncan_opening\ncar_horn\nmouse_click\nmouse_click\ncrying_baby\nmouse_click\nmouse_click\nmouse_click\nmouse_click\nsea_waves\nhen\npig\npig\npig\npig\ninsects\nairplane\nfireworks\npig\npig\npig\nglass_breaking\nglass_breaking\nglass_breaking\nsheep\nsheep\nhand_saw\ncrackling_fire\ncrackling_fire\nhelicopter\nhelicopter\nhelicopter\nhelicopter\nsheep\nwind\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nfootsteps\nglass_breaking\nclapping\nclapping\ntrain\ncrackling_fire\ncrackling_fire\ncrackling_fire\ncrackling_fire\nfrog\nfrog\nfrog\nfrog\nfrog\nhelicopter\nhelicopter\nhelicopter\nhelicopter\npig\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\ncar_horn\nsiren\nsiren\ncrying_baby\ncrying_baby\nchainsaw\nchainsaw\nchainsaw\nchainsaw\nbreathing\nwashing_machine\nhand_saw\nhand_saw\nsnoring\nsnoring\nfrog\nfrog\nfrog\ncar_horn\nbreathing\nbreathing\nchurch_bells\nchurch_bells\nclapping\nwashing_machine\nhand_saw\nchurch_bells\nchurch_bells\nhand_saw\nhand_saw\nlaughing\nlaughing\nlaughing\nclapping\ncrackling_fire\nchurch_bells\nlaughing\ntoilet_flush\nwater_drops\nwater_drops\ntoilet_flush\ncrackling_fire\nrooster\nbreathing\ncrying_baby\ncrying_baby\ntoilet_flush\nchainsaw\nchainsaw\nwater_drops\nwater_drops\ncat\ncat\nsiren\nsiren\ntoilet_flush\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\nsiren\nsiren\nsiren\nrooster\nhen\nchirping_birds\nchirping_birds\nchirping_birds\nchirping_birds\ntoilet_flush\nsiren\nrain\nrain\ndoor_wood_creaks\nrain\nbrushing_teeth\nairplane\ntoilet_flush\nhen\nclapping\nclapping\nclapping\nclapping\nhen\nchurch_bells\nchurch_bells\nchainsaw\nchainsaw\nchurch_bells\nclock_alarm\nclock_alarm\nengine\nairplane\nairplane\nlaughing\nlaughing\nsnoring\ncrying_baby\ncrickets\ncan_opening\ncan_opening\nrooster\nrain\ninsects\ninsects\ninsects\nbrushing_teeth\ninsects\ncat\ncat\nrain\nbreathing\nsneezing\ncrickets\nbrushing_teeth\ncan_opening\ncan_opening\ncat\ncat\nhand_saw\ntoilet_flush\nbreathing\ncrickets\ncoughing\nbrushing_teeth\ncan_opening\ntoilet_flush\nbrushing_teeth\ncan_opening\ncoughing\ndoor_wood_creaks\nrain\ncoughing\ncoughing\ncoughing\nclock_tick\nclock_alarm\ndoor_wood_creaks\ndoor_wood_creaks\nbrushing_teeth\ndrinking_sipping\nsneezing\nbrushing_teeth\ndrinking_sipping\nrooster\nrooster\nrooster\nbreathing\ncrickets\nclock_alarm\nrooster\nairplane\nbrushing_teeth\nbreathing\ncoughing\nairplane\nkeyboard_typing\nkeyboard_typing\ninsects\ninsects\ninsects\ntoilet_flush\nbrushing_teeth\nbrushing_teeth\ndoor_wood_creaks\ndoor_wood_creaks\nhand_saw\nhand_saw\nhand_saw\nfrog\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\nfootsteps\nfootsteps\nfootsteps\nfootsteps\ncrackling_fire\ninsects\ninsects\ncrackling_fire\ninsects\ninsects\nlaughing\nrooster\nbreathing\npouring_water\npouring_water\ntoilet_flush\ntoilet_flush\nlaughing\ninsects\ninsects\ninsects\ninsects\nchurch_bells\nchurch_bells\ntoilet_flush\ncrow\nbrushing_teeth\nbreathing\nbreathing\nengine\nairplane\nairplane\nairplane\nrooster\ncrow\nwind\nwind\nclock_alarm\nclock_alarm\ntoilet_flush\nbrushing_teeth\nbrushing_teeth\ndoor_wood_creaks\nlaughing\nchainsaw\nchainsaw\nchainsaw\nchainsaw\nchainsaw\nchainsaw\nchainsaw\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nengine\nlaughing\nclock_alarm\nclock_alarm\ncrackling_fire\ncrow\nchurch_bells\nsnoring\nthunderstorm\ncow\ncow\nthunderstorm\nsnoring\ncrow\nsnoring\ncoughing\nkeyboard_typing\nlaughing\ncow\ncow\nbrushing_teeth\nbrushing_teeth\npouring_water\ncrow\ncrow\ncrow\nengine\nairplane\nairplane\ncrow\ncrickets\ncrickets\nclapping\nsnoring\nsnoring\nclock_alarm\nclock_alarm\ncoughing\nlaughing\nkeyboard_typing\nrain\ndrinking_sipping\nrooster\nwind\nwind\nwind\ncrickets\nwashing_machine\ntrain\ntrain\ndog\ntrain\nwind\nrooster\nclapping\ntrain\nchurch_bells\nbrushing_teeth\nclock_alarm\nsheep\nsheep\nsheep\nsheep\ndrinking_sipping\nrain\nengine\nengine\ntrain\nsneezing\nrain\nrain\npouring_water\nclock_tick\nsneezing\ncoughing\nsneezing\nsneezing\nairplane\nairplane\nrain\nclock_tick\ndog\nkeyboard_typing\nkeyboard_typing\nbreathing\nbreathing\ndrinking_sipping\ndrinking_sipping\ndoor_wood_knock\nsneezing\nsea_waves\nsea_waves\nthunderstorm\nthunderstorm\nrooster\ndrinking_sipping\ncoughing\ncar_horn\npouring_water\ncrackling_fire\ncrickets\nengine\ncar_horn\ncoughing\ncat\ncat\ncat\ncan_opening\ncan_opening\ncrackling_fire\nclock_alarm\nsneezing\ncan_opening\ncoughing\nrooster\npouring_water\nclapping\nsneezing\nclock_tick\nhelicopter\nhelicopter\nhelicopter\ncrying_baby\ncrying_baby\ncrying_baby\ndoor_wood_knock\nbreathing\ncoughing\ncoughing\nsnoring\nwashing_machine\nwashing_machine\nsnoring\nsnoring\ncrying_baby\ncrying_baby\ncrying_baby\ncrying_baby\ncrying_baby\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\ncow\ncow\ndoor_wood_knock\nlaughing\nlaughing\ncar_horn\nkeyboard_typing\ndoor_wood_knock\npouring_water\nengine\nkeyboard_typing\nhelicopter\nhelicopter\nrooster\ncar_horn\ncar_horn\ndog\nmouse_click\nkeyboard_typing\nkeyboard_typing\nchirping_birds\nchirping_birds\nchirping_birds\nchirping_birds\nchirping_birds\nsea_waves\nsea_waves\ncan_opening\ncrickets\nwashing_machine\nwashing_machine\nsneezing\nchirping_birds\nchirping_birds\nwater_drops\nrain\ncrackling_fire\nrain\ntrain\nrain\ndog\nmouse_click\nmouse_click\ncrackling_fire\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\ntrain\ntrain\nwater_drops\ncow\ncar_horn\npouring_water\ncrickets\nrooster\ndog\ncrickets\ncrickets\ncow\nsea_waves\nhen\nhen\nhen\nwater_drops\nwater_drops\nwater_drops\nwater_drops\nsea_waves\nclock_tick\nchainsaw\nbreathing\nbreathing\nwater_drops\nwater_drops\nsea_waves\ncan_opening\ncan_opening\nmouse_click\ndrinking_sipping\ncan_opening\ndog\nmouse_click\nclock_tick\nclock_tick\ndoor_wood_knock\nmouse_click\nclock_tick\nclock_tick\nhen\ncan_opening\nmouse_click\nfireworks\nfireworks\ncar_horn\ndrinking_sipping\nclapping\nclapping\nhen\ndoor_wood_knock\ndog\ndog\nchirping_birds\nclapping\ndoor_wood_knock\ndoor_wood_knock\nwashing_machine\nwashing_machine\nmouse_click\ndrinking_sipping\nhen\nhen\nsea_waves\nhen\nwashing_machine\nairplane\nsheep\nsheep\nsheep\nclapping\nclapping\nglass_breaking\nglass_breaking\nglass_breaking\nglass_breaking\nglass_breaking\nsheep\nhand_saw\nglass_breaking\nglass_breaking\nglass_breaking\npig\ncar_horn\nwind\nwind\nfootsteps\nfireworks\npig\npig\npig\npig\npig\npig\npig\nengine\nsiren\nsiren\nsiren\nsiren\nsiren\nsiren\nsiren\nsiren\ncrackling_fire\nhelicopter\nhelicopter\nhelicopter\nfrog\nfrog\nfrog\nfrog\nfrog\nfrog\nfrog\nchurch_bells\nchurch_bells\ntoilet_flush\ntoilet_flush\nfootsteps\nfootsteps\nfootsteps\ndoor_wood_creaks\ncat\ncat\ncat\ncat\ncat\nhand_saw\nhand_saw\nhand_saw\nhand_saw\nchurch_bells\ntoilet_flush\nchurch_bells\nhand_saw\nhand_saw\nhand_saw\nsiren\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\ndoor_wood_creaks\nsiren\nsiren\nfootsteps\nfootsteps\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\ntoilet_flush\ncat\nsiren\ntoilet_flush\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\nchurch_bells\nchurch_bells\nhelicopter\ntoilet_flush\ntoilet_flush\ndoor_wood_creaks\nfrog\ninsects\npig\npig\nlaughing\nlaughing\nlaughing\ndoor_wood_creaks\ncat\ncat\ncat\nlaughing\ninsects\ntoilet_flush\ncrow\ncrow\nchurch_bells\ntoilet_flush\ninsects\ninsects\nwind\nwind\nwind\nwind\nbrushing_teeth\nbrushing_teeth\ntoilet_flush\ncrow\nvacuum_cleaner\npig\npig\nchurch_bells\nchurch_bells\nchainsaw\nchainsaw\ncat\ncat\nchurch_bells\nchurch_bells\nclock_alarm\ntoilet_flush\ncoughing\nbrushing_teeth\nbrushing_teeth\ncoughing\nfrog\ncoughing\ncoughing\nlaughing\ncrow\nchurch_bells\nsneezing\nsneezing\nthunderstorm\ncoughing\nsneezing\nchainsaw\nchainsaw\nkeyboard_typing\ncrow\nchirping_birds\nchirping_birds\ndoor_wood_creaks\ndoor_wood_creaks\nrain\nairplane\nairplane\nairplane\nairplane\nairplane\nairplane\nrain\ncat\ncat\nthunderstorm\nhelicopter\nhelicopter\nrain\nwind\nwind\nwind\nwind\ncrickets\nrooster\nrooster\nrooster\nrooster\nrain\nlaughing\ncrackling_fire\ncrackling_fire\nrooster\ntrain\ntrain\ntrain\nthunderstorm\nthunderstorm\nchainsaw\nchainsaw\ntrain\ntrain\ntrain\nrain\nsea_waves\nsea_waves\nsea_waves\ncrying_baby\ncrying_baby\ncrying_baby\nkeyboard_typing\nlaughing\nsneezing\nwater_drops\ntrain\npouring_water\nchainsaw\nchainsaw\nclock_alarm\ncoughing\nrooster\ncrackling_fire\ncrackling_fire\ncrackling_fire\ncoughing\nsneezing\nengine\nbreathing\ncrickets\ncrickets\nkeyboard_typing\nclock_alarm\npouring_water\nbrushing_teeth\nbrushing_teeth\nbrushing_teeth\nbrushing_teeth\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\nkeyboard_typing\ncrow\ncrow\nwater_drops\ncow\ncow\nhelicopter\nhelicopter\nhelicopter\ncan_opening\ncar_horn\ncar_horn\ncar_horn\ncar_horn\nclock_tick\ncar_horn\ncar_horn\nbreathing\nkeyboard_typing\nrain\ncoughing\ncar_horn\ntrain\ncan_opening\nclock_tick\nsnoring\nrain\npouring_water\nclock_tick\nrain\ncrickets\ncrackling_fire\nlaughing\npouring_water\nkeyboard_typing\nkeyboard_typing\nclock_tick\ncow\ncow\ncow\nvacuum_cleaner\ndoor_wood_knock\ndoor_wood_knock\ndoor_wood_knock\ninsects\ninsects\ncrackling_fire\ncrackling_fire\ndog\nsea_waves\nsea_waves\nchirping_birds\npouring_water\nrooster\nsnoring\nsnoring\ndog\nsnoring\nsnoring\nsneezing\ndog\nsneezing\ncrying_baby\ncrying_baby\ncrying_baby\nkeyboard_typing\nsneezing\ndoor_wood_knock\npouring_water\nengine\nengine\nengine\nengine\nengine\ndoor_wood_knock\ncan_opening\npouring_water\npouring_water\nchirping_birds\nchirping_birds\ncan_opening\nclock_tick\ndrinking_sipping\ndrinking_sipping\ndrinking_sipping\ncrow\nwater_drops\nwater_drops\ndrinking_sipping\nsheep\nsheep\nsheep\nsheep\ndoor_wood_knock\nclock_alarm\nclapping\nclapping\nclapping\nclapping\nclapping\nclapping\nclapping\ncar_horn\ninsects\ninsects\nsnoring\nclock_tick\ndog\nmouse_click\ndog\nhelicopter\nhelicopter\ncrickets\nvacuum_cleaner\nclock_tick\ndog\ndrinking_sipping\nfootsteps\nfootsteps\nmouse_click\nengine\nsea_waves\nsea_waves\ncrickets\ncrickets\nsheep\nsheep\nsheep\nhen\nsnoring\nsnoring\nwater_drops\nbreathing\nhand_saw\nhand_saw\nhand_saw\nclock_alarm\nfootsteps\nfootsteps\nclock_tick\ndog\nhen\nhen\nmouse_click\nmouse_click\nengine\nmouse_click\ncrickets\nglass_breaking\nglass_breaking\nglass_breaking\nglass_breaking\ndrinking_sipping\nmouse_click\nsea_waves\nmouse_click\nclock_alarm\nglass_breaking\nglass_breaking\nglass_breaking\nhen\nbreathing\nbreathing\nclapping\nbreathing\ndog\nrooster\nclock_alarm\nclock_alarm\nbreathing\nbreathing\nmouse_click\ndrinking_sipping\ndoor_wood_knock\nwater_drops\nwater_drops\nwater_drops\nglass_breaking\ncan_opening\ndrinking_sipping\ncow\ncow\ncow\ncan_opening\nchirping_birds\ncan_opening\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\nwashing_machine\nfootsteps\nfootsteps\nchirping_birds\nchirping_birds\nhen\npig\nhen\nhen\nsheep\npig\npig\npig\nhand_saw\nhand_saw\nairplane\nhen\nairplane\ndoor_wood_knock\ncan_opening\ncrying_baby\ncrying_baby\nsiren\nsiren\nsiren\nsiren\nfrog\nfrog\nfrog\nfrog\nfrog\nfrog\npig\npig\npig\npig\npig\npig\nsiren\nsiren\nsiren\npig\nwind\npig\nsiren\nsiren\nwashing_machine\nbrushing_teeth\nsiren\ncrying_baby\nfrog\nfrog\nfrog\nfrog\ntoilet_flush\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\nthunderstorm\nwind\nwind\nsiren\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\nfireworks\ndoor_wood_creaks\ndoor_wood_creaks\ncat\nchainsaw\nchainsaw\nlaughing\nchainsaw\ncat\ncat\ndoor_wood_creaks\ntoilet_flush\ncat\ndoor_wood_creaks\nhelicopter\nhelicopter\nhelicopter\nhelicopter\nhelicopter\ncoughing\nchurch_bells\nwind\nwind\ncar_horn\ncar_horn\ncar_horn\ncar_horn\ncar_horn\ncar_horn\ncar_horn\ncar_horn\nbrushing_teeth\ndoor_wood_creaks\nrain\nwashing_machine\nvacuum_cleaner\nvacuum_cleaner\nvacuum_cleaner\ntoilet_flush\nsiren\ncoughing\nbrushing_teeth\nchainsaw\nchainsaw\ntoilet_flush\ncrackling_fire\nfrog\nfrog\ndoor_wood_creaks\nsneezing\nvacuum_cleaner\nthunderstorm\ndoor_wood_creaks\nrain\nchurch_bells\ntrain\ntrain\ncrackling_fire\ncrackling_fire\nfrog\nhelicopter\ndoor_wood_creaks\nthunderstorm\nrain\ncrackling_fire\ncrackling_fire\nsneezing\nrain\ncow\ncow\ncow\ncow\nrooster\nrooster\ninsects\ninsects\ninsects\nthunderstorm\nrain\ntrain\ntrain\ntrain\ninsects\ntoilet_flush\nchurch_bells\ninsects\ninsects\ninsects\nrain\nchurch_bells\ncrying_baby\ncrying_baby\ncrying_baby\ncrying_baby\ncrying_baby\ncrying_baby\ncrying_baby\ntrain\nsheep\nsheep\nsheep\nsheep\ntrain\ntrain\nsheep\nsheep\nsheep\nrooster\nrooster\nrooster\nsea_waves\nsea_waves\nchurch_bells\nchurch_bells\nclock_tick\nsneezing\ntoilet_flush\ntoilet_flush\nsneezing\ntoilet_flush\ncow\nrain\ndog\ndog\nrain\ndrinking_sipping\ncrickets\ncrickets\ncoughing\nchurch_bells\nkeyboard_typing\npouring_water\npouring_water\nhelicopter\ncoughing\npouring_water\nwashing_machine\nwashing_machine\ndrinking_sipping\ndrinking_sipping\ndrinking_sipping\ndrinking_sipping\ndog\nclock_tick\ncoughing\nsea_waves\nsea_waves\nclock_tick\ncoughing\nclock_tick\nclapping\nengine\nengine\ncrickets\nclock_tick\nclock_alarm\ncoughing\nclock_alarm\nbrushing_teeth\nvacuum_cleaner\nvacuum_cleaner\nclock_tick\ndog\npouring_water\npouring_water\npouring_water\nsea_waves\nbreathing\ncrackling_fire\ncrow\ncrow\ncrow\ncrow\ndog\npouring_water\ncat\ncat\ncrow\nkeyboard_typing\ncrickets\ncrickets\nairplane\nairplane\nairplane\npouring_water\ncrackling_fire\ncrackling_fire\nkeyboard_typing\ncrickets\ncrickets\ncrickets\nsnoring\nchainsaw\nchainsaw\ndog\nwind\nwind\nwind\nbrushing_teeth\nbrushing_teeth\nclapping\ndoor_wood_knock\ndoor_wood_knock\nchurch_bells\nclock_alarm\nclock_alarm\nmouse_click\nclock_tick\nsea_waves\nsea_waves\nsea_waves\nsneezing\nsneezing\nbrushing_teeth\nhelicopter\nsneezing\nglass_breaking\nglass_breaking\nclapping\nclapping\nsneezing\ncan_opening\nclapping\ncrow\nchainsaw\nkeyboard_typing\nkeyboard_typing\nkeyboard_typing\nmouse_click\nclock_alarm\nmouse_click\nwashing_machine\nvacuum_cleaner\ndog\nengine\nmouse_click\nbreathing\nmouse_click\nrooster\nbreathing\nsnoring\nglass_breaking\nglass_breaking\nclock_alarm\ninsects\nsnoring\nclock_alarm\nfootsteps\nbreathing\nfootsteps\nrooster\nrooster\nkeyboard_typing\nengine\nbreathing\ndoor_wood_knock\nclock_tick\nsnoring\nsnoring\nairplane\nsnoring\ncan_opening\nmouse_click\nfrog\ncan_opening\nwashing_machine\nbreathing\nmouse_click\nbrushing_teeth\nengine\nwater_drops\nchirping_birds\nchirping_birds\ncow\ncrow\nlaughing\nlaughing\nfootsteps\ndrinking_sipping\nchirping_birds\nchirping_birds\nchirping_birds\nchirping_birds\nchirping_birds\ndrinking_sipping\nengine\nengine\nengine\nkeyboard_typing\nfootsteps\nhen\nhen\nhen\ncan_opening\nsnoring\nlaughing\nmouse_click\ncan_opening\nwashing_machine\nhen\nhen\nhen\nsnoring\nclapping\ndoor_wood_knock\ndoor_wood_knock\nhand_saw\nclock_alarm\ncan_opening\ndoor_wood_knock\ndoor_wood_knock\ncoughing\nairplane\nairplane\nairplane\nairplane\ncan_opening\ncow\ncow\nhand_saw\nhand_saw\nhand_saw\nhand_saw\nhand_saw\nhand_saw\nhand_saw\nlaughing\nclapping\nwater_drops\nwater_drops\ncat\ndoor_wood_knock\nwater_drops\nglass_breaking\nchirping_birds\ncat\nwater_drops\nlaughing\ndrinking_sipping\ncan_opening\nbreathing\nglass_breaking\nglass_breaking\nglass_breaking\nwashing_machine\ncrow\nwater_drops\nwater_drops\nbreathing\nwater_drops\nclapping\nfootsteps\nfootsteps\nfootsteps\nlaughing\nlaughing\nhen\nhen\nvacuum_cleaner\nfootsteps\nsheep\ndog\nFinished feature extraction from  2000  files\n"
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '../ESC-50/audio/'\n",
    "\n",
    "metadata = pd.read_csv('../ESC-50/meta/esc50.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),str(row[\"filename\"]))\n",
    "    class_label = row[\"category\"]\n",
    "    print(class_label)\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 216\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 39, 215, 16)       80        \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 19, 107, 16)       0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 19, 107, 16)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 18, 106, 32)       2080      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 9, 53, 32)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 9, 53, 32)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 8, 52, 64)         8256      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 4, 26, 64)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 4, 26, 64)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 3, 25, 128)        32896     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 1, 12, 128)        0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1, 12, 128)        0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 50)                6450      \n=================================================================\nTotal params: 49,762\nTrainable params: 49,762\nNon-trainable params: 0\n_________________________________________________________________\n400/400 [==============================] - 1s 3ms/step\nPre-training accuracy: 1.0000%\n"
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 [==============================] - 0s 73us/step - loss: 0.1154 - accuracy: 0.9625 - val_loss: 3.1885 - val_accuracy: 0.5525\n\nEpoch 00003: val_loss improved from 3.28279 to 3.18850, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 4/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0960 - accuracy: 0.9700 - val_loss: 3.2263 - val_accuracy: 0.5400\n\nEpoch 00004: val_loss did not improve from 3.18850\nEpoch 5/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1265 - accuracy: 0.9519 - val_loss: 3.1728 - val_accuracy: 0.5450\n\nEpoch 00005: val_loss improved from 3.18850 to 3.17283, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 6/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1153 - accuracy: 0.9600 - val_loss: 3.1613 - val_accuracy: 0.5525\n\nEpoch 00006: val_loss improved from 3.17283 to 3.16130, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 7/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1187 - accuracy: 0.9600 - val_loss: 3.2355 - val_accuracy: 0.5350\n\nEpoch 00007: val_loss did not improve from 3.16130\nEpoch 8/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1087 - accuracy: 0.9638 - val_loss: 3.1717 - val_accuracy: 0.5525\n\nEpoch 00008: val_loss did not improve from 3.16130\nEpoch 9/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1196 - accuracy: 0.9575 - val_loss: 3.2328 - val_accuracy: 0.5600\n\nEpoch 00009: val_loss did not improve from 3.16130\nEpoch 10/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1195 - accuracy: 0.9619 - val_loss: 3.1495 - val_accuracy: 0.5625\n\nEpoch 00010: val_loss improved from 3.16130 to 3.14952, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 11/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1052 - accuracy: 0.9619 - val_loss: 3.1460 - val_accuracy: 0.5275\n\nEpoch 00011: val_loss improved from 3.14952 to 3.14602, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 12/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1110 - accuracy: 0.9650 - val_loss: 3.1416 - val_accuracy: 0.5475\n\nEpoch 00012: val_loss improved from 3.14602 to 3.14162, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 13/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1076 - accuracy: 0.9644 - val_loss: 3.1612 - val_accuracy: 0.5550\n\nEpoch 00013: val_loss did not improve from 3.14162\nEpoch 14/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1087 - accuracy: 0.9638 - val_loss: 3.1695 - val_accuracy: 0.5650\n\nEpoch 00014: val_loss did not improve from 3.14162\nEpoch 15/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1075 - accuracy: 0.9650 - val_loss: 3.1884 - val_accuracy: 0.5475\n\nEpoch 00015: val_loss did not improve from 3.14162\nEpoch 16/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1117 - accuracy: 0.9656 - val_loss: 3.3875 - val_accuracy: 0.5275\n\nEpoch 00016: val_loss did not improve from 3.14162\nEpoch 17/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1497 - accuracy: 0.9563 - val_loss: 3.1576 - val_accuracy: 0.5400\n\nEpoch 00017: val_loss did not improve from 3.14162\nEpoch 18/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1285 - accuracy: 0.9588 - val_loss: 3.1424 - val_accuracy: 0.5425\n\nEpoch 00018: val_loss did not improve from 3.14162\nEpoch 19/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1445 - accuracy: 0.9519 - val_loss: 3.3146 - val_accuracy: 0.5300\n\nEpoch 00019: val_loss did not improve from 3.14162\nEpoch 20/100\n1600/1600 [==============================] - 0s 79us/step - loss: 0.1303 - accuracy: 0.9606 - val_loss: 3.0759 - val_accuracy: 0.5625\n\nEpoch 00020: val_loss improved from 3.14162 to 3.07589, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 21/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1221 - accuracy: 0.9556 - val_loss: 3.0567 - val_accuracy: 0.5700\n\nEpoch 00021: val_loss improved from 3.07589 to 3.05669, saving model to saveModels/weights.best.basic_cnn.hdf5\nEpoch 22/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1041 - accuracy: 0.9706 - val_loss: 3.1598 - val_accuracy: 0.5500\n\nEpoch 00022: val_loss did not improve from 3.05669\nEpoch 23/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1112 - accuracy: 0.9613 - val_loss: 3.3025 - val_accuracy: 0.5525\n\nEpoch 00023: val_loss did not improve from 3.05669\nEpoch 24/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1094 - accuracy: 0.9638 - val_loss: 3.2283 - val_accuracy: 0.5450\n\nEpoch 00024: val_loss did not improve from 3.05669\nEpoch 25/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1117 - accuracy: 0.9631 - val_loss: 3.1907 - val_accuracy: 0.5525\n\nEpoch 00025: val_loss did not improve from 3.05669\nEpoch 26/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0936 - accuracy: 0.9688 - val_loss: 3.2965 - val_accuracy: 0.5575\n\nEpoch 00026: val_loss did not improve from 3.05669\nEpoch 27/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0982 - accuracy: 0.9744 - val_loss: 3.2773 - val_accuracy: 0.5500\n\nEpoch 00027: val_loss did not improve from 3.05669\nEpoch 28/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1091 - accuracy: 0.9644 - val_loss: 3.2088 - val_accuracy: 0.5450\n\nEpoch 00028: val_loss did not improve from 3.05669\nEpoch 29/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0917 - accuracy: 0.9688 - val_loss: 3.2977 - val_accuracy: 0.5425\n\nEpoch 00029: val_loss did not improve from 3.05669\nEpoch 30/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1261 - accuracy: 0.9575 - val_loss: 3.1446 - val_accuracy: 0.5450\n\nEpoch 00030: val_loss did not improve from 3.05669\nEpoch 31/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1073 - accuracy: 0.9644 - val_loss: 3.2971 - val_accuracy: 0.5425\n\nEpoch 00031: val_loss did not improve from 3.05669\nEpoch 32/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0903 - accuracy: 0.9719 - val_loss: 3.2710 - val_accuracy: 0.5600\n\nEpoch 00032: val_loss did not improve from 3.05669\nEpoch 33/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0942 - accuracy: 0.9694 - val_loss: 3.1406 - val_accuracy: 0.5725\n\nEpoch 00033: val_loss did not improve from 3.05669\nEpoch 34/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1009 - accuracy: 0.9675 - val_loss: 3.1911 - val_accuracy: 0.5675\n\nEpoch 00034: val_loss did not improve from 3.05669\nEpoch 35/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1016 - accuracy: 0.9725 - val_loss: 3.3394 - val_accuracy: 0.5450\n\nEpoch 00035: val_loss did not improve from 3.05669\nEpoch 36/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0817 - accuracy: 0.9719 - val_loss: 3.2907 - val_accuracy: 0.5400\n\nEpoch 00036: val_loss did not improve from 3.05669\nEpoch 37/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0883 - accuracy: 0.9725 - val_loss: 3.2458 - val_accuracy: 0.5575\n\nEpoch 00037: val_loss did not improve from 3.05669\nEpoch 38/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1301 - accuracy: 0.9613 - val_loss: 3.3412 - val_accuracy: 0.5475\n\nEpoch 00038: val_loss did not improve from 3.05669\nEpoch 39/100\n1600/1600 [==============================] - 0s 70us/step - loss: 0.1119 - accuracy: 0.9644 - val_loss: 3.4743 - val_accuracy: 0.5250\n\nEpoch 00039: val_loss did not improve from 3.05669\nEpoch 40/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1116 - accuracy: 0.9700 - val_loss: 3.3697 - val_accuracy: 0.5425\n\nEpoch 00040: val_loss did not improve from 3.05669\nEpoch 41/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0956 - accuracy: 0.9675 - val_loss: 3.3309 - val_accuracy: 0.5675\n\nEpoch 00041: val_loss did not improve from 3.05669\nEpoch 42/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0935 - accuracy: 0.9756 - val_loss: 3.2865 - val_accuracy: 0.5875\n\nEpoch 00042: val_loss did not improve from 3.05669\nEpoch 43/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1097 - accuracy: 0.9669 - val_loss: 3.1867 - val_accuracy: 0.5750\n\nEpoch 00043: val_loss did not improve from 3.05669\nEpoch 44/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1031 - accuracy: 0.9650 - val_loss: 3.2222 - val_accuracy: 0.5500\n\nEpoch 00044: val_loss did not improve from 3.05669\nEpoch 45/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0786 - accuracy: 0.9731 - val_loss: 3.1973 - val_accuracy: 0.5550\n\nEpoch 00045: val_loss did not improve from 3.05669\nEpoch 46/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0970 - accuracy: 0.9675 - val_loss: 3.2379 - val_accuracy: 0.5650\n\nEpoch 00046: val_loss did not improve from 3.05669\nEpoch 47/100\n1600/1600 [==============================] - 0s 70us/step - loss: 0.1014 - accuracy: 0.9619 - val_loss: 3.2919 - val_accuracy: 0.5500\n\nEpoch 00047: val_loss did not improve from 3.05669\nEpoch 48/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0958 - accuracy: 0.9663 - val_loss: 3.3053 - val_accuracy: 0.5625\n\nEpoch 00048: val_loss did not improve from 3.05669\nEpoch 49/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0855 - accuracy: 0.9706 - val_loss: 3.2492 - val_accuracy: 0.5700\n\nEpoch 00049: val_loss did not improve from 3.05669\nEpoch 50/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0820 - accuracy: 0.9762 - val_loss: 3.2868 - val_accuracy: 0.5650\n\nEpoch 00050: val_loss did not improve from 3.05669\nEpoch 51/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1040 - accuracy: 0.9644 - val_loss: 3.3062 - val_accuracy: 0.5650\n\nEpoch 00051: val_loss did not improve from 3.05669\nEpoch 52/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1147 - accuracy: 0.9606 - val_loss: 3.2335 - val_accuracy: 0.5400\n\nEpoch 00052: val_loss did not improve from 3.05669\nEpoch 53/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0811 - accuracy: 0.9725 - val_loss: 3.2885 - val_accuracy: 0.5475\n\nEpoch 00053: val_loss did not improve from 3.05669\nEpoch 54/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1335 - accuracy: 0.9569 - val_loss: 3.2945 - val_accuracy: 0.5525\n\nEpoch 00054: val_loss did not improve from 3.05669\nEpoch 55/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0916 - accuracy: 0.9756 - val_loss: 3.4825 - val_accuracy: 0.5300\n\nEpoch 00055: val_loss did not improve from 3.05669\nEpoch 56/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1275 - accuracy: 0.9631 - val_loss: 3.3726 - val_accuracy: 0.5325\n\nEpoch 00056: val_loss did not improve from 3.05669\nEpoch 57/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1063 - accuracy: 0.9675 - val_loss: 3.2746 - val_accuracy: 0.5625\n\nEpoch 00057: val_loss did not improve from 3.05669\nEpoch 58/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0997 - accuracy: 0.9631 - val_loss: 3.3663 - val_accuracy: 0.5425\n\nEpoch 00058: val_loss did not improve from 3.05669\nEpoch 59/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0803 - accuracy: 0.9756 - val_loss: 3.5068 - val_accuracy: 0.5525\n\nEpoch 00059: val_loss did not improve from 3.05669\nEpoch 60/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0628 - accuracy: 0.9812 - val_loss: 3.3817 - val_accuracy: 0.5650\n\nEpoch 00060: val_loss did not improve from 3.05669\nEpoch 61/100\n1600/1600 [==============================] - 0s 70us/step - loss: 0.0877 - accuracy: 0.9712 - val_loss: 3.3572 - val_accuracy: 0.5850\n\nEpoch 00061: val_loss did not improve from 3.05669\nEpoch 62/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.1003 - accuracy: 0.9688 - val_loss: 3.2894 - val_accuracy: 0.5625\n\nEpoch 00062: val_loss did not improve from 3.05669\nEpoch 63/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1217 - accuracy: 0.9625 - val_loss: 3.3790 - val_accuracy: 0.5475\n\nEpoch 00063: val_loss did not improve from 3.05669\nEpoch 64/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1310 - accuracy: 0.9663 - val_loss: 3.2547 - val_accuracy: 0.5800\n\nEpoch 00064: val_loss did not improve from 3.05669\nEpoch 65/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1147 - accuracy: 0.9600 - val_loss: 3.4202 - val_accuracy: 0.5600\n\nEpoch 00065: val_loss did not improve from 3.05669\nEpoch 66/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0994 - accuracy: 0.9625 - val_loss: 3.3787 - val_accuracy: 0.5600\n\nEpoch 00066: val_loss did not improve from 3.05669\nEpoch 67/100\n1600/1600 [==============================] - 0s 70us/step - loss: 0.0850 - accuracy: 0.9719 - val_loss: 3.4275 - val_accuracy: 0.5475\n\nEpoch 00067: val_loss did not improve from 3.05669\nEpoch 68/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 3.3994 - val_accuracy: 0.5600\n\nEpoch 00068: val_loss did not improve from 3.05669\nEpoch 69/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0909 - accuracy: 0.9712 - val_loss: 3.3970 - val_accuracy: 0.5650\n\nEpoch 00069: val_loss did not improve from 3.05669\nEpoch 70/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0626 - accuracy: 0.9781 - val_loss: 3.4160 - val_accuracy: 0.5575\n\nEpoch 00070: val_loss did not improve from 3.05669\nEpoch 71/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0937 - accuracy: 0.9731 - val_loss: 3.4051 - val_accuracy: 0.5725\n\nEpoch 00071: val_loss did not improve from 3.05669\nEpoch 72/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0791 - accuracy: 0.9769 - val_loss: 3.5191 - val_accuracy: 0.5375\n\nEpoch 00072: val_loss did not improve from 3.05669\nEpoch 73/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0783 - accuracy: 0.9750 - val_loss: 3.4914 - val_accuracy: 0.5450\n\nEpoch 00073: val_loss did not improve from 3.05669\nEpoch 74/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0947 - accuracy: 0.9688 - val_loss: 3.4059 - val_accuracy: 0.5475\n\nEpoch 00074: val_loss did not improve from 3.05669\nEpoch 75/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0891 - accuracy: 0.9681 - val_loss: 3.3577 - val_accuracy: 0.5650\n\nEpoch 00075: val_loss did not improve from 3.05669\nEpoch 76/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0617 - accuracy: 0.9819 - val_loss: 3.3846 - val_accuracy: 0.5800\n\nEpoch 00076: val_loss did not improve from 3.05669\nEpoch 77/100\n1600/1600 [==============================] - 0s 70us/step - loss: 0.0760 - accuracy: 0.9762 - val_loss: 3.3989 - val_accuracy: 0.5650\n\nEpoch 00077: val_loss did not improve from 3.05669\nEpoch 78/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0547 - accuracy: 0.9850 - val_loss: 3.5226 - val_accuracy: 0.5500\n\nEpoch 00078: val_loss did not improve from 3.05669\nEpoch 79/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0726 - accuracy: 0.9787 - val_loss: 3.4167 - val_accuracy: 0.5675\n\nEpoch 00079: val_loss did not improve from 3.05669\nEpoch 80/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0788 - accuracy: 0.9756 - val_loss: 3.4259 - val_accuracy: 0.5725\n\nEpoch 00080: val_loss did not improve from 3.05669\nEpoch 81/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 3.5075 - val_accuracy: 0.5550\n\nEpoch 00081: val_loss did not improve from 3.05669\nEpoch 82/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 3.6193 - val_accuracy: 0.5600\n\nEpoch 00082: val_loss did not improve from 3.05669\nEpoch 83/100\n1600/1600 [==============================] - 0s 70us/step - loss: 0.0654 - accuracy: 0.9762 - val_loss: 3.5221 - val_accuracy: 0.5775\n\nEpoch 00083: val_loss did not improve from 3.05669\nEpoch 84/100\n1600/1600 [==============================] - 0s 71us/step - loss: 0.0668 - accuracy: 0.9769 - val_loss: 3.5011 - val_accuracy: 0.5700\n\nEpoch 00084: val_loss did not improve from 3.05669\nEpoch 85/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0816 - accuracy: 0.9731 - val_loss: 3.3736 - val_accuracy: 0.5800\n\nEpoch 00085: val_loss did not improve from 3.05669\nEpoch 86/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0789 - accuracy: 0.9775 - val_loss: 3.4273 - val_accuracy: 0.5775\n\nEpoch 00086: val_loss did not improve from 3.05669\nEpoch 87/100\n1600/1600 [==============================] - 0s 76us/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 3.5342 - val_accuracy: 0.5550\n\nEpoch 00087: val_loss did not improve from 3.05669\nEpoch 88/100\n1600/1600 [==============================] - 0s 76us/step - loss: 0.0967 - accuracy: 0.9688 - val_loss: 3.7234 - val_accuracy: 0.5475\n\nEpoch 00088: val_loss did not improve from 3.05669\nEpoch 89/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.1158 - accuracy: 0.9644 - val_loss: 3.5667 - val_accuracy: 0.5475\n\nEpoch 00089: val_loss did not improve from 3.05669\nEpoch 90/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0908 - accuracy: 0.9656 - val_loss: 3.5123 - val_accuracy: 0.5425\n\nEpoch 00090: val_loss did not improve from 3.05669\nEpoch 91/100\n1600/1600 [==============================] - 0s 74us/step - loss: 0.0881 - accuracy: 0.9731 - val_loss: 3.5173 - val_accuracy: 0.5300\n\nEpoch 00091: val_loss did not improve from 3.05669\nEpoch 92/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0752 - accuracy: 0.9756 - val_loss: 3.5536 - val_accuracy: 0.5325\n\nEpoch 00092: val_loss did not improve from 3.05669\nEpoch 93/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0872 - accuracy: 0.9744 - val_loss: 3.5088 - val_accuracy: 0.5375\n\nEpoch 00093: val_loss did not improve from 3.05669\nEpoch 94/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 3.6359 - val_accuracy: 0.5350\n\nEpoch 00094: val_loss did not improve from 3.05669\nEpoch 95/100\n1600/1600 [==============================] - 0s 73us/step - loss: 0.0634 - accuracy: 0.9825 - val_loss: 3.5966 - val_accuracy: 0.5400\n\nEpoch 00095: val_loss did not improve from 3.05669\nEpoch 96/100\n1600/1600 [==============================] - 0s 74us/step - loss: 0.0903 - accuracy: 0.9694 - val_loss: 3.5202 - val_accuracy: 0.5625\n\nEpoch 00096: val_loss did not improve from 3.05669\nEpoch 97/100\n1600/1600 [==============================] - 0s 76us/step - loss: 0.0842 - accuracy: 0.9737 - val_loss: 3.3448 - val_accuracy: 0.5875\n\nEpoch 00097: val_loss did not improve from 3.05669\nEpoch 98/100\n1600/1600 [==============================] - 0s 74us/step - loss: 0.0836 - accuracy: 0.9756 - val_loss: 3.5802 - val_accuracy: 0.5325\n\nEpoch 00098: val_loss did not improve from 3.05669\nEpoch 99/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.1007 - accuracy: 0.9613 - val_loss: 3.3407 - val_accuracy: 0.5900\n\nEpoch 00099: val_loss did not improve from 3.05669\nEpoch 100/100\n1600/1600 [==============================] - 0s 72us/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 3.2724 - val_accuracy: 0.5950\n\nEpoch 00100: val_loss did not improve from 3.05669\nTraining completed in time:  0:00:12.072170\n"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saveModels/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training Accuracy:  0.996874988079071\nTesting Accuracy:  0.5950000286102295\n"
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}